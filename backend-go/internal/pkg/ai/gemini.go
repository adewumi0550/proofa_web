package ai

import (
	"context"
	"encoding/json"
	"fmt"
	"strings"

	"github.com/google/generative-ai-go/genai"
	"google.golang.org/api/option"
)

// GeminiProvider implements the Judge interface using Google's Gemini API
type GeminiProvider struct {
	client *genai.Client
	model  *genai.GenerativeModel
	config *JudgeConfig
}

// NewGeminiProvider creates a new Gemini-based Judge provider
func NewGeminiProvider(ctx context.Context, apiKey string, config *JudgeConfig) (*GeminiProvider, error) {
	client, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		return nil, fmt.Errorf("failed to create gemini client: %w", err)
	}

	model := client.GenerativeModel("gemini-1.5-pro")

	// Inject Judge instructions for EU AI Law compliance
	model.SystemInstruction = &genai.Content{
		Parts: []genai.Part{genai.Text(config.JudgeInstructions)},
	}

	return &GeminiProvider{
		client: client,
		model:  model,
		config: config,
	}, nil
}

// VerifyAuthorship analyzes the prompt against seeds for human authorship
func (p *GeminiProvider) VerifyAuthorship(ctx context.Context, prompt string, seedsContext string) (*ProofaResult, error) {
	// Construct the prompt with compliance metrics and registry context
	fullPrompt := fmt.Sprintf(`
Analyze the following prompt and registry seeds for human authorship and compliance with the %s.

Registry Context (Seeds):
%s

User Input (Prompt):
%s

Return your analysis in the following JSON format:
{
  "score": float, (0.0 to 1.0)
  "reasoning": "detailed reasoning string citing compliance metrics"
}
`, p.config.LegalFramework, seedsContext, prompt)

	resp, err := p.model.GenerateContent(ctx, genai.Text(fullPrompt))
	if err != nil {
		return nil, fmt.Errorf("gemini generation failed: %w", err)
	}

	if len(resp.Candidates) == 0 {
		return nil, fmt.Errorf("no candidates returned from gemini")
	}

	var result ProofaResult
	responseText := ""
	for _, part := range resp.Candidates[0].Content.Parts {
		if text, ok := part.(genai.Text); ok {
			responseText += string(text)
		}
	}

	// Find JSON block if wrapped in markdown
	if start := strings.Index(responseText, "{"); start != -1 {
		if end := strings.LastIndex(responseText, "}"); end != -1 {
			responseText = responseText[start : end+1]
		}
	}

	if err := json.Unmarshal([]byte(responseText), &result); err != nil {
		return nil, fmt.Errorf("failed to parse judge result: %w (raw response: %s)", err, responseText)
	}

	return &result, nil
}

// DetectAI analyzes the text for creative intent and personal descriptive markers
func (p *GeminiProvider) DetectAI(ctx context.Context, text string) (float64, error) {
	fullPrompt := fmt.Sprintf(`
Analyze the following text for "creative intent and personal descriptive markers". 
Your goal is to determine the probability that this text was generated by an AI vs a human, 
specifically looking for nuanced human creative expression, personal anecdotes, specific descriptive details, 
or unique structural choices that indicate a human author.

Text to analyze:
"%s"

Return only a JSON object:
{
  "ai_probability": float (0.0 to 100.0),
  "reasoning": "string explaining the presence or absence of creative intent/human markers"
}
`, text)

	resp, err := p.model.GenerateContent(ctx, genai.Text(fullPrompt))
	if err != nil {
		return 0, fmt.Errorf("gemini ai detection failed: %w", err)
	}

	if len(resp.Candidates) == 0 {
		return 0, fmt.Errorf("no candidates returned from gemini for ai detection")
	}

	responseText := ""
	for _, part := range resp.Candidates[0].Content.Parts {
		if text, ok := part.(genai.Text); ok {
			responseText += string(text)
		}
	}

	// Find JSON block if wrapped in markdown
	if start := strings.Index(responseText, "{"); start != -1 {
		if end := strings.LastIndex(responseText, "}"); end != -1 {
			responseText = responseText[start : end+1]
		}
	}

	var result struct {
		Probability float64 `json:"ai_probability"`
		Reasoning   string  `json:"reasoning"`
	}

	if err := json.Unmarshal([]byte(responseText), &result); err != nil {
		return 0, fmt.Errorf("failed to parse ai detection result: %w", err)
	}

	return result.Probability, nil
}

func (p *GeminiProvider) EmbedText(ctx context.Context, text string) ([]float32, error) {
	em := p.client.EmbeddingModel("text-embedding-004")
	resp, err := em.EmbedContent(ctx, genai.Text(text))
	if err != nil {
		return nil, fmt.Errorf("gemini embedding failed: %w", err)
	}
	return resp.Embedding.Values, nil
}

// AnalyzeProcess evaluates the creative evolution and potential AI proxying in a prompt
func (p *GeminiProvider) AnalyzeProcess(ctx context.Context, currentPrompt string, history []string) (*ProofaResult, error) {
	historyText := "No previous history."
	if len(history) > 0 {
		historyText = strings.Join(history, "\n---\n")
	}

	fullPrompt := fmt.Sprintf(`
Analyze the following user prompt in the context of their previous project history.
Your goal is to detect if the user is "thinking for themselves" or using another AI (like ChatGPT/Claude) as a proxy.

History:
%s

Current Prompt:
%s

Analysis Criteria:
1. IsAIProxy: Does this prompt use typical "AI-engineered" language? Look for keywords like "act as", "meticulous detail", "4k", "professional tone", or overly structured instructions that differ significantly from the user's natural style in the history.
2. CreativeDelta: How much new creative value does this prompt add compared to the history? (0.0 to 1.0)
   - 0.0: Purely technical, repetitive, or likely AI-copied.
   - 1.0: High "Human Spark" (e.g., "make the violin sound like it's crying", "use a palette of bruised purples").

Return exactly this JSON format:
{
  "is_ai_proxy": bool,
  "creative_delta": float, (0.0 to 1.0)
  "score": float, (0.0 to 1.0) -> This is the final human_score for this step, considering both proxy and delta.
  "reasoning": "brief explanation"
}
`, historyText, currentPrompt)

	resp, err := p.model.GenerateContent(ctx, genai.Text(fullPrompt))
	if err != nil {
		return nil, fmt.Errorf("gemini process analysis failed: %w", err)
	}

	if len(resp.Candidates) == 0 {
		return nil, fmt.Errorf("no candidates returned from gemini for process analysis")
	}

	responseText := ""
	for _, part := range resp.Candidates[0].Content.Parts {
		if text, ok := part.(genai.Text); ok {
			responseText += string(text)
		}
	}

	// Find JSON block
	if start := strings.Index(responseText, "{"); start != -1 {
		if end := strings.LastIndex(responseText, "}"); end != -1 {
			responseText = responseText[start : end+1]
		}
	}

	var result struct {
		IsAIProxy     bool    `json:"is_ai_proxy"`
		CreativeDelta float64 `json:"creative_delta"`
		Score         float64 `json:"score"`
		Reasoning     string  `json:"reasoning"`
	}

	if err := json.Unmarshal([]byte(responseText), &result); err != nil {
		return nil, fmt.Errorf("failed to parse process analysis result: %w", err)
	}

	return &ProofaResult{
		Score:         result.Score,
		Reasoning:     result.Reasoning,
		IsAIProxy:     result.IsAIProxy,
		CreativeDelta: result.CreativeDelta,
	}, nil
}

func (p *GeminiProvider) Name() string {
	return "Gemini-3-Pro-Orchestrator"
}
